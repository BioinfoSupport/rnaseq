---
title: "Cutadapt Quality Control"
output: html_document
params:
  cutadapt_dir: "data/fastq/soldati/tnseq/Foulon_fastq"
---

The `.fastq.gz` files you receive from the genomic platform contains the sequenced reads.
The analysis pipeline can trim adapter sequences with cutadapt a generate a file called `_cutadapt.json` containing summary statistics of the adapter trimming process. This notebook aggregate multiple of them and display their content so we can have an overview of the coherence of the trimming process.

This notebook take as input a working directory, and load the content of all files with extension `.json`.



```{r setup, include=FALSE}
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	echo = FALSE
)
library(ggplot2)
library(tidyverse)

read_cutadapt_json <- function(f) {
	jsonlite::fromJSON(f)
}
```


```{r}
# Load content of all _cutadapt.json files in the given folder
x <- list.files(params$cutadapt_dir,"_cutadapt.json",full.names = TRUE) |>
	enframe(value = "path",name = NULL) |>
	mutate(content = map(path,read_cutadapt_json)) |> 
	mutate(path = fct(path)) |>
	mutate(lib = fct_relabel(path,~str_replace(basename(.),"(_umi)?_cutadapt.json$","")))
```


# Read size distribution
```{r fig.height=15, fig.width=5}
x |>
	mutate(content = map(x$content,~.x$adapters_read1$five_prime_end$trimmed_lengths[[1]])) |>
	unnest(content) |>
	unnest_longer(counts,indices_to = "err") |>
	mutate(err = factor(err - 1L)) |>
	ggplot(aes(x=len,y=counts,fill=err)) + 
		facet_grid(lib~.) +
		scale_y_continuous(labels = scales::label_number(scale_cut = scales::cut_short_scale())) +
		geom_col() + 
		theme(legend.position="top",strip.text.y = element_text(angle=0))
```








