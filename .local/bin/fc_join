#!/usr/bin/env Rscript



#-#-#-#-#-#-#-#-#-#-#-#-#
# Argument parsing
#-#-#-#-#-#-#-#-#-#-#-#-#
library(optparse)
option_list <- list( 
	make_option("--out",help="name of the RDS file to create with SummarizedExperiment object [default: %default]",type="character",default="out.rds")
)
opt <- parse_args(OptionParser(
	usage = "usage: %prog --out <bam-file> ...",
	description = "Merge counts generated by the pipeline for multiple BAM files. For each given 'file.bam', the files 'file.bam.stat' and 'file.bam.fc must exists and will be loaded into a SummarizedExperiment object.'",
	option_list = option_list
	),positional_arguments = c(1, Inf))
if (is.null(opt$options$"out")) stop("--out argument is required")


#-#-#-#-#-#-#-#-#-#-#-#-#
# Methods definitions
#-#-#-#-#-#-#-#-#-#-#-#-#
suppressPackageStartupMessages({
	#BiocParallel::register(BiocParallel::SerialParam(progressbar = TRUE)) # Alternative running in non-parallel mode
	BiocParallel::register(BiocParallel::MulticoreParam(workers=3,progressbar = TRUE))
	library(SummarizedExperiment)
	library(GenomicAlignments)
	library(tidyverse)
  library(AnnotationDbi)
})


# Parse text files containing mapping statistics generated by HISAT2
read_ht2_stat <- function(stat.files) {
	ht2_read_stat_1 <- function(f) {
		txt <- readLines(f)
		sequenced <- ".*Total reads: *([0-9]+).*$" %>% sub(.,"\\1",grep(.,txt,value=TRUE)) %>% as.integer()
		unmap <- ".*Aligned 0 time: *([0-9]+).*$" %>% sub(.,"\\1",grep(.,txt,value=TRUE)) %>% as.integer()
		uniqmap <- ".*Aligned 1 time: *([0-9]+).*$" %>% sub(.,"\\1",grep(.,txt,value=TRUE)) %>% as.integer()
		multimap <- ".*Aligned >1 times: *([0-9]+).*$" %>% sub(.,"\\1",grep(.,txt,value=TRUE)) %>% as.integer()
		c(sequenced=sequenced,unmap=unmap,uniqmap=uniqmap,multimap=multimap)
	}
	BiocParallel::bplapply(stat.files,ht2_read_stat_1) |>
		simplify2array() |>
		t() |>
		as.data.frame()
}


read_fc <- function(bam_files,default_counts="genomicU") {
	# bam_files <- list.files("data/fastq/pilot",".ht2.bam$",recursive=TRUE,full.names=TRUE)
	# List BAM files to extract genome information
	bam_files <- BamFileList(bam_files)
	
	# Load counts and feature sizes
	x <- sub(".bam$",".bam.fc",path(bam_files)) |>
		BiocParallel::bplapply(read.table,header=TRUE,sep="\t") |>
		bind_rows(.id="lib") |>
		mutate(lib=factor(lib,names(bam_files)))
	
	# Extract gene count matrix
	n <- with(
		filter(x,feature_type %in% "gene"),
		tapply(count,list(feature_id,lib,count_type),identity)
	)
	
	# Create SummarizedExperiment object
	e <- SummarizedExperiment(
		apply(n,3,identity,simplify = FALSE)
	)
	rowData(e)$feature_id <- rownames(e)
	assays(e) <- c(List(counts=assay(e,default_counts)),assays(e))
	assay(e,"counts")[is.na(assay(e,"counts"))] <- 0L
	e$path <- path(bam_files)
	e$lib <- colnames(e)
	
	# Extract stats by chromosome
	metadata(e)$seqinfo <- seqinfo(bam_files)
	metadata(e)$chrom_stats <- filter(x,feature_type %in% "chrom")
	
	# Extract feature sizes
	feature_sizes <- filter(x,feature_type %in% "gene") |>
		mutate(count_type = sub("[ASU]$","",count_type)) |>
		distinct(feature_id,count_type,feature_size) |>
		pivot_wider(id_cols="feature_id",names_from = "count_type",values_from = "feature_size")
	mcols(e)$feature_size <- feature_sizes[match(rownames(e),feature_sizes$feature_id),-1L]
	
	e
}


#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#
# Main
#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#
x <- read_fc(opt$args)
colData(x) <- as(read_ht2_stat(sub(".bam$",".stat",opt$args)),"DataFrame")
saveRDS(x,file=opt$options$out)






